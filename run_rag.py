import argparse
import json
from src.data_util.pdf_extractor import PDFExtractor
from src.index_db.index import Faiss_Index
from src.chatbot.model import RAG_Pipeline
from huggingface_hub import login
import os


def main(args=None):
    """
    Main function to run the Biology RAG Question and Answering system.
    
    This function initializes the system, loads configuration, prepares data,
    and processes user queries to generate answers using the RAG model.
    
    Steps:
    1. Load API key from configuration and log in to Hugging Face.
    2. Parse command line arguments for data paths, model, and query.
    3. Check and prepare the input data path.
    4. Extract text from PDF if not already extracted.
    5. Check and build the FAISS index if not already available.
    6. Initialize the RAG pipeline with the model and generate answers to the query.
    
    Command Line Arguments:
        --input_data_path (str): Path to the biology textbook PDF/Extracted Text.
        --start_page (int): Starting page number for text extraction from the PDF.
        --end_page (int): Ending page number for text extraction from the PDF.
        --index_path (str): Path where the FAISS index files are stored or will be stored.
        --index_model (str): Model identifier for the sentence transformer model used in FAISS index.
        --model_name (str): Model identifier on Hugging Face for the RAG model.
        --query (str): Query to be asked from the Language Learning Model (LLM).
    
    Returns:
        str: The answer generated by the RAG model for the provided query.
    
    Raises:
        FileNotFoundError: If the specified input data path or index files are not found.
        KeyError: If 'api_key' is missing from the JSON configuration file.
        json.JSONDecodeError: If the JSON configuration file is malformed.
        PermissionError: If there is a permission error accessing provided paths.
        ValueError: If the API key is empty.
        Exception: For any other unforeseen errors.
    """
    try:
        with open('./env/config.json', 'r') as file:
            config = json.load(file)
        api_key = config['api_key']
        login(token=api_key)
        if not api_key:
            raise ValueError("API key is empty.")
    except FileNotFoundError:
        print("Error: Config file not exists! please place your config file in the path './env/config.json'")
    except KeyError:
        print("Error: The 'api_key' is missing from the JSON file.")
    except json.JSONDecodeError:
        print("Error: JSON decoding error occurred.")
    except Exception as e:
        print(f"Error: {e}")

    parser = argparse.ArgumentParser(description="Biology RAG Question and Answering")
    parser.add_argument('--input_data_path', type=str, default="./data/", help="Path to the biology textbook PDF/Extracted Text")
    parser.add_argument('--start_page', type=int, default=18, help="Starting page number for text extraction")
    parser.add_argument('--end_page', type=int, default=73, help="Ending page number for text extraction")
    parser.add_argument('--index_path', type=str, default="./db_files/", help="Path where the FAISS index files are stored or will be stored")
    parser.add_argument('--index_model', type=str, default="sentence-transformers/all-MiniLM-l6-v2", help="Model identifier for the sentence transformer model used in FAISS index")
    parser.add_argument('--model_name', type=str, default="mistralai/Mistral-7B-v0.1", help="Model identifier on Hugging Face for the RAG model")
    parser.add_argument('--query', type=str, required=True, help="Query to be asked from the Language Learning Model (LLM)")
    
    if args is not None:
        
        args = parser.parse_args(args)
    else:
        
        args = parser.parse_args()
    

    print(args.input_data_path)

    try:
        if os.path.exists(str(args.input_data_path)):
            print(f"Input path: '{args.input_data_path}' exists.")
        else:
            raise FileNotFoundError(f"The folder '{args.input_data_path}' was not found.")
    except PermissionError:
        print(f"Permission denied: Cannot access '{args.input_data_path}'.")
    except FileNotFoundError as e:
        print(e)
    except Exception as e:
        print(f"An error occurred: {e}")

    path_to_extracted_data = os.path.join(args.input_data_path, "extracted_chapters.txt")
    print(path_to_extracted_data)
    if os.path.exists(path_to_extracted_data):
        print(f"Already extracted data present at '{path_to_extracted_data}'")
    else:
        print("Extracted Text doesn't exist and extracting now")

        obj_pdf = PDFExtractor(args.input_data_path)
        t = obj_pdf.extract_text_from_pdf("ConceptsofBiology-WEB.pdf", args.start_page, args.end_page)
        obj_pdf.save_text_local("extracted_chapters.txt", t)

    index_file1 = os.path.join(args.index_path, 'index.faiss')
    index_file2 = os.path.join(args.index_path, 'index.pkl')

    ind_obj = Faiss_Index(args.index_path, args.index_model)

    if os.path.exists(index_file1) and os.path.exists(index_file2):
        print(f"FAISS index already available at '{args.index_path}'")
    else:
        print("FAISS Index is locally not available")
        vector_store = ind_obj.create_index_text(path_to_extracted_data)
        ind_obj.index_to_local(vector_store)

    rag_pipeline = RAG_Pipeline(args.input_data_path, args.model_name)
    vector_store_loaded = ind_obj.local_to_index()
    response = rag_pipeline.generate_answer(args.query, vector_store_loaded)
    answer = rag_pipeline.extract_answer(response)
    #print(answer)

    return answer


if __name__ == '__main__':
    answer = main()
    print("===========================================================")
    print("-------------Generated Answer------------------------------")
    print("===========================================================")
    print(answer)
